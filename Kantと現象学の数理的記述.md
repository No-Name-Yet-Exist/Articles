Kantと現象学を数理モデルに落とし込みます。哲学って数学に書き直せるの？と思った方には面白いと思います。

※これは数学で書かれた文章であり試論です。正しさを証明するものではなく、構造の挙動を観察することを目的としています。

### Noumenon/Phenomenaとは
Noumenonはモノ自体であり、Phenomena(現象)はそれを我々が感じ取っているものになります。ざっくりと犬とその写真で対応します。

### 以前との違い

以前Kantについて数理モデルを作りましたが、どうやら現象に直接アクセスすることは禁止されていないようです。なので今回は前回のように遠慮せず現象をまじまじと見つめに行きます。とはいっても対象が同じなので、基本のアプローチは変わらないです。ある意味読み替えです。
Kantの数理モデル

まず現象のメタ観察を式に落とし込みます。
P(X) = X * R
R = 観察後の現象 / 観察前の現象

Rは情報損失率を意味します。観察行為は基本的に情報の変質、欠損を伴うのでそれをモデル化しています。関数P(X)は現象を観察した後に入れ子で得られる現象、または事象(?)です。

k階層目のメタ観察です。
k(P) = P(P^(k-1)(P0))
P0は一番最初の現象

∞階層のメタ観察における極限の値を計算します。
lim​ k→∞ P(k)(P0)
P0=1とする
計算結果の解釈

R>1
こちらは情報が発散しますが、そもそもR>1の時点で解釈が元の情報量を超えています。人間のリソースは限られているので、現象が今見ている世界と、メタに見た世界と倍以上になった時点で、メモリオーバーフローして下の階層に侵入します。現実的な例に落とし込むと、妄想状態や幻覚に近くなると思われます。高次階層における解釈データが逆流して、低次階層におけるデータを汚染しだします。下の例はメタ認知データ領域からの逆流汚染に見える例です。
例 私は監視されてる 私は選ばれしものだ　私は神だ

R=1
k=0であるならば成り立ちます。要は我々が住む場所だからです。しかし1階層以降は飛躍的に情報量※1が増加するためメモリ的に厳しいです。例を挙げるなら1階層ですら2つの映画を完全無欠の解像度で同時再生してるのと同じになります。実感としても個人差あるにしてもメタ認知はそんな解像度はないと思います。
※1
ここで言う情報量は階層を上がるごとに保持される情報量総体を意味しており、極限の計算に関わるものではないです。

R<1 0収束
こちらは0収束します。working memory的にも感覚的にもこちらが自然です。0収束の解釈としては最初のモノ自体から連続的に非本質的な情報がそぎ落とされることで、モノ自体(Noumenon)の中核構造に漸近すると解釈できます。ここでリアルさを上げるならフィードバックとして、下の階層のメモリ量の圧縮という再計算を入れるといいかもしれません。


# 現象学の数理モデル

現象学における還元はその場限りで完結するものではなく、ある一定の時間において繰り返し行われるものと解釈すると、Rtの微分方程式で書き表せます。この式の解釈として、眠いと還元力は落ちるといったように解釈できたりします。

dR_S/dt = -α_S * R_S + β_S * I_S

第一項 -α_S * R_S​：自然減衰（減衰定数 × 現在の漸近率）
第二項 β_S * I_S：外的・内的な還元インパルスによる加算効果

RS​：Noumenon漸近率 / モノそれ自体の中核構造への漸近
α_S：自然な情報損失の速度
β_S：個人の還元力（メタ認知力など）
I_S：還元の強度